{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d711bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0890b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存放输出数据的文件夹\n",
    "root_dir: str = \"database/working\"\n",
    "# 存放临时数据的文件夹\n",
    "tmp_dir: str = \"database/\"\n",
    "# lora的名称\n",
    "lora_name: str = \"juzhisam\"\n",
    "# 加密密钥\n",
    "encrypt_key: str = None\n",
    "\n",
    "config_dict = {\n",
    "\t\"network_arguments\": {\n",
    "\t\t\"unet_lr\": 3e-4*4, # UNet 学习率\n",
    "\t\t\"text_encoder_lr\": 6e-5*4, # TextEncoder 学习率\n",
    "\t\t\"network_dim\": 16, # LORA的大小\n",
    "\t\t\"network_alpha\": 8,\n",
    "\n",
    "\t\t\"network_module\": \"networks.lora\",\n",
    "\t\t\"network_args\": None,\n",
    "\t\t\"network_train_unet_only\": False,\n",
    "\t},\n",
    "\t\"optimizer_arguments\": {\n",
    "\t\t# lr_scheduler: [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\"]\n",
    "\t\t\"lr_scheduler\": \"cosine_with_restarts\",\n",
    "\t\t\"lr_scheduler_num_cycles\": 3,\n",
    "\t\t\"lr_scheduler_power\": None,\n",
    "\t\t\"lr_warmup_steps\": 0,\n",
    "\n",
    "\t\t# optimizer: [\"AdamW8bit\", \"Prodigy\", \"DAdaptation\", \"DadaptAdam\", \"DadaptLion\", \"AdamW\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
    "\t\t\"optimizer_type\": \"AdamW8bit\",\n",
    "\t\t\"optimizer_args\": [\n",
    "\t\t\t\"weight_decay=0.1\", \n",
    "\t\t\t\"betas=[0.9,0.99]\"\n",
    "\t\t],\n",
    "\t},\n",
    "\t\"training_arguments\": {\n",
    "\t\t# 模型文件\n",
    "\t\t\"pretrained_model_name_or_path\": \"D:\\\\GITHUB\\\\stable-diffusion-webui\\\\models\\\\Stable-diffusion\\\\yiffymix_v61Noobxl.safetensors\",\n",
    "\n",
    "\t\t# vae 文件\n",
    "\t\t# - \"stabilityai/sdxl-vae\": 使用 huggingface 模型\n",
    "\t\t# - None: 使用模型自带的vae\n",
    "\t\t\"vae\": None,\n",
    "\n",
    "\t\t\"max_train_epochs\": 15, # 训练多少epoch\n",
    "\t\t\"train_batch_size\": 2, # 训练的批大小\n",
    "\n",
    "\t\t# 尽可能直接加载到vram而不是ram中\n",
    "\t\t\"lowram\": True,\n",
    "\n",
    "\t\t# mixed precision: [\"bf16\", \"fp16\"]\n",
    "\t\t\"mixed_precision\": \"fp16\",\n",
    "\n",
    "\t\t# 二选一\n",
    "\t\t\"xformers\": False,\n",
    "\t\t\"sdpa\": True,\n",
    "\n",
    "\t\t\"cache_latents\": True,\n",
    "\t\t\"cache_latents_to_disk\": True,\n",
    "\t\t\"cache_text_encoder_outputs\": False,\n",
    "\t\t\"seed\": 42,\n",
    "\t\t\"max_token_length\": 225,\n",
    "\t\t\"min_snr_gamma\": 7.0,\n",
    "\t\t\"no_half_vae\": True,\n",
    "\t\t\"gradient_checkpointing\": True,\n",
    "\t\t\"gradient_accumulation_steps\": 1,\n",
    "\t\t\"max_data_loader_n_workers\": 8,\n",
    "\t\t\"persistent_data_loader_workers\": True,\n",
    "\t\t\"min_timestep\": 0,\n",
    "\t\t\"max_timestep\": 1000,\n",
    "\t\t\"prior_loss_weight\": 1.0,\n",
    "\t},\n",
    "\t\"saving_arguments\": {\n",
    "\t\t# 保存的精度\n",
    "\t\t\"save_precision\": \"fp16\",\n",
    "\t\t# 保存的格式\n",
    "\t\t\"save_model_as\": \"safetensors\",\n",
    "\t\t\n",
    "\t\t# 保存的频率\n",
    "\t\t\"save_every_n_epochs\": 1,\n",
    "\t\t\"save_last_n_epochs\": 15,\n",
    "\t\t\n",
    "\t\t\"output_name\": lora_name,\n",
    "\t\t\"log_prefix\": lora_name,\n",
    "\t}\n",
    "}\n",
    "\n",
    "dataset_dict = {\n",
    "\t\"general\": {\n",
    "\t\t# 是否需要打乱标签\n",
    "\t\t\"shuffle_caption\": True,\n",
    "\t\t# 保持前几个标签不打乱\n",
    "\t\t\"keep_tokens\": 1,\n",
    "\n",
    "\t\t# 训练的分辨率\n",
    "\t\t\"resolution\": 1024,\n",
    "\t\t\"flip_aug\": False,\n",
    "\t\t\"caption_extension\": \".txt\",\n",
    "\t\t\"enable_bucket\": True,\n",
    "\t\t\"bucket_no_upscale\": True,\n",
    "\t\t\"bucket_reso_steps\": 64,\n",
    "\t\t\"min_bucket_reso\": 256,\n",
    "\t\t\"max_bucket_reso\": 4096,\n",
    "\t},\n",
    "\t# 数据集，可设置多个数据集\n",
    "\t\"datasets\": [{\n",
    "\t\t\"subsets\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t# 数据重复几次\n",
    "\t\t\t\t\"num_repeats\": 5,\n",
    "\t\t\t\t# 数据集路径，最终会自动复制到tmpdir目录下使用\n",
    "\t\t\t\t\"image_dir\": \"D:\\\\GITHUB\\\\sd-scripts\\\\samples\\\\juzhi\",\n",
    "\t\t\t\t# 是否使用mep加密，设为None表示不使用，设为true表示使用\n",
    "\t\t\t\t\"cache_info\": None,\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ab26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Train config saved to database/working\\juzhisam\\configs\\training_config.toml\n",
      "📄 Dataset config saved to database/working\\juzhisam\\configs\\dataset_config.toml\n",
      "Configuration already exists at database/working\\juzhisam\\configs\\accelerate_config\\config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "📄 Accelerate config saved to database/working\\juzhisam\\configs\\accelerate_config\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "config_dict[\"optimizer_arguments\"][\"learning_rate\"] = config_dict[\"network_arguments\"][\"unet_lr\"]\n",
    "config_dict[\"training_arguments\"][\"full_bf16\"] = (config_dict[\"training_arguments\"][\"mixed_precision\"] == \"bf16\")\n",
    "config_dict[\"training_arguments\"][\"full_fp16\"] = (config_dict[\"training_arguments\"][\"mixed_precision\"] == \"fp16\")\n",
    "\n",
    "workingdir = os.path.join(root_dir, lora_name)\n",
    "configdir = os.path.join(workingdir, \"configs\")\n",
    "logdir = os.path.join(workingdir, \"logs\")\n",
    "outputdir = os.path.join(workingdir, \"outputs\")\n",
    "datasetdir = os.path.join(tmp_dir, \"dataset\")\n",
    "\n",
    "for x in [workingdir, configdir, logdir, outputdir, datasetdir]:\n",
    "\tos.makedirs(x, exist_ok = True)\n",
    "\n",
    "config_dict[\"saving_arguments\"][\"output_dir\"] = os.path.abspath(outputdir)\n",
    "config_dict[\"saving_arguments\"][\"logging_dir\"] = os.path.abspath(logdir)\n",
    "\n",
    "resolution = dataset_dict[\"general\"][\"resolution\"]\n",
    "temp_resolution = round(resolution / 128) * 128\n",
    "if (resolution != temp_resolution):\n",
    "\tresolution = temp_resolution\n",
    "\tprint(\"⚠️ resolution is rouned to nearest step: \", resolution)\n",
    "\tdataset_dict[\"general\"][\"resolution\"] = resolution\n",
    "\n",
    "for i in range(len(dataset_dict[\"datasets\"][0][\"subsets\"])):\n",
    "\ttargetfolder = os.path.join(datasetdir, str(i))\n",
    "\tif os.path.exists(targetfolder):\n",
    "\t\tshutil.rmtree(targetfolder)\n",
    "\tshutil.copytree(dataset_dict[\"datasets\"][0][\"subsets\"][i][\"image_dir\"], targetfolder)\n",
    "\tdataset_dict[\"datasets\"][0][\"subsets\"][i][\"image_dir\"] = os.path.abspath(targetfolder)\n",
    "\n",
    "def CleanConfigAndSave(name: str, filename: str, config_dict: dict):\n",
    "\tfor key in config_dict:\n",
    "\t\tif isinstance(config_dict[key], dict):\n",
    "\t\t\tconfig_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
    "\t\n",
    "\twith open(filename, \"w\") as f:\n",
    "\t\tf.write(toml.dumps(config_dict))\n",
    "\n",
    "\tprint(f\"📄 {name} config saved to {filename}\")\n",
    "\n",
    "config_file = os.path.join(configdir, \"training_config.toml\")\n",
    "CleanConfigAndSave(\"Train\", config_file, config_dict)\n",
    "\n",
    "dataset_file = os.path.join(configdir, \"dataset_config.toml\")\n",
    "CleanConfigAndSave(\"Dataset\", dataset_file, dataset_dict)\n",
    "\n",
    "accelerate_file = os.path.join(configdir, \"accelerate_config\", \"config.yaml\")\n",
    "from accelerate.utils import write_basic_config\n",
    "write_basic_config(save_location=accelerate_file)\n",
    "print(f\"📄 Accelerate config saved to {accelerate_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bab4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⭐ Starting trainer...\n"
     ]
    }
   ],
   "source": [
    "print(\"⭐ Starting trainer...\")\n",
    "\n",
    "#!accelerate launch --config_file={accelerate_file} --num_cpu_threads_per_process=1 --mixed_precision={config_dict[\"training_arguments\"][\"mixed_precision\"]} train_network_xl_wrapper.py --dataset_config={dataset_file} --config_file={config_file} --mep_key {encrypt_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31ca325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train_network_xl_wrapper.py --dataset_config={dataset_file} --config_file={config_file} --mep_key {encrypt_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
