{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d711bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0890b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­˜æ”¾è¾“å‡ºæ•°æ®çš„æ–‡ä»¶å¤¹\n",
    "root_dir: str = \"database/working\"\n",
    "# å­˜æ”¾ä¸´æ—¶æ•°æ®çš„æ–‡ä»¶å¤¹\n",
    "tmp_dir: str = \"database/\"\n",
    "# loraçš„åç§°\n",
    "lora_name: str = \"juzhisam\"\n",
    "# åŠ å¯†å¯†é’¥\n",
    "encrypt_key: str = None\n",
    "\n",
    "config_dict = {\n",
    "\t\"network_arguments\": {\n",
    "\t\t\"unet_lr\": 3e-4*4, # UNet å­¦ä¹ ç‡\n",
    "\t\t\"text_encoder_lr\": 6e-5*4, # TextEncoder å­¦ä¹ ç‡\n",
    "\t\t\"network_dim\": 16, # LORAçš„å¤§å°\n",
    "\t\t\"network_alpha\": 8,\n",
    "\n",
    "\t\t\"network_module\": \"networks.lora\",\n",
    "\t\t\"network_args\": None,\n",
    "\t\t\"network_train_unet_only\": False,\n",
    "\t},\n",
    "\t\"optimizer_arguments\": {\n",
    "\t\t# lr_scheduler: [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\"]\n",
    "\t\t\"lr_scheduler\": \"cosine_with_restarts\",\n",
    "\t\t\"lr_scheduler_num_cycles\": 3,\n",
    "\t\t\"lr_scheduler_power\": None,\n",
    "\t\t\"lr_warmup_steps\": 0,\n",
    "\n",
    "\t\t# optimizer: [\"AdamW8bit\", \"Prodigy\", \"DAdaptation\", \"DadaptAdam\", \"DadaptLion\", \"AdamW\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
    "\t\t\"optimizer_type\": \"AdamW8bit\",\n",
    "\t\t\"optimizer_args\": [\n",
    "\t\t\t\"weight_decay=0.1\", \n",
    "\t\t\t\"betas=[0.9,0.99]\"\n",
    "\t\t],\n",
    "\t},\n",
    "\t\"training_arguments\": {\n",
    "\t\t# æ¨¡å‹æ–‡ä»¶\n",
    "\t\t\"pretrained_model_name_or_path\": \"D:\\\\GITHUB\\\\stable-diffusion-webui\\\\models\\\\Stable-diffusion\\\\yiffymix_v61Noobxl.safetensors\",\n",
    "\n",
    "\t\t# vae æ–‡ä»¶\n",
    "\t\t# - \"stabilityai/sdxl-vae\": ä½¿ç”¨ huggingface æ¨¡å‹\n",
    "\t\t# - None: ä½¿ç”¨æ¨¡å‹è‡ªå¸¦çš„vae\n",
    "\t\t\"vae\": None,\n",
    "\n",
    "\t\t\"max_train_epochs\": 15, # è®­ç»ƒå¤šå°‘epoch\n",
    "\t\t\"train_batch_size\": 2, # è®­ç»ƒçš„æ‰¹å¤§å°\n",
    "\n",
    "\t\t# å°½å¯èƒ½ç›´æ¥åŠ è½½åˆ°vramè€Œä¸æ˜¯ramä¸­\n",
    "\t\t\"lowram\": True,\n",
    "\n",
    "\t\t# mixed precision: [\"bf16\", \"fp16\"]\n",
    "\t\t\"mixed_precision\": \"fp16\",\n",
    "\n",
    "\t\t# äºŒé€‰ä¸€\n",
    "\t\t\"xformers\": False,\n",
    "\t\t\"sdpa\": True,\n",
    "\n",
    "\t\t\"cache_latents\": True,\n",
    "\t\t\"cache_latents_to_disk\": True,\n",
    "\t\t\"cache_text_encoder_outputs\": False,\n",
    "\t\t\"seed\": 42,\n",
    "\t\t\"max_token_length\": 225,\n",
    "\t\t\"min_snr_gamma\": 7.0,\n",
    "\t\t\"no_half_vae\": True,\n",
    "\t\t\"gradient_checkpointing\": True,\n",
    "\t\t\"gradient_accumulation_steps\": 1,\n",
    "\t\t\"max_data_loader_n_workers\": 8,\n",
    "\t\t\"persistent_data_loader_workers\": True,\n",
    "\t\t\"min_timestep\": 0,\n",
    "\t\t\"max_timestep\": 1000,\n",
    "\t\t\"prior_loss_weight\": 1.0,\n",
    "\t},\n",
    "\t\"saving_arguments\": {\n",
    "\t\t# ä¿å­˜çš„ç²¾åº¦\n",
    "\t\t\"save_precision\": \"fp16\",\n",
    "\t\t# ä¿å­˜çš„æ ¼å¼\n",
    "\t\t\"save_model_as\": \"safetensors\",\n",
    "\t\t\n",
    "\t\t# ä¿å­˜çš„é¢‘ç‡\n",
    "\t\t\"save_every_n_epochs\": 1,\n",
    "\t\t\"save_last_n_epochs\": 15,\n",
    "\t\t\n",
    "\t\t\"output_name\": lora_name,\n",
    "\t\t\"log_prefix\": lora_name,\n",
    "\t}\n",
    "}\n",
    "\n",
    "dataset_dict = {\n",
    "\t\"general\": {\n",
    "\t\t# æ˜¯å¦éœ€è¦æ‰“ä¹±æ ‡ç­¾\n",
    "\t\t\"shuffle_caption\": True,\n",
    "\t\t# ä¿æŒå‰å‡ ä¸ªæ ‡ç­¾ä¸æ‰“ä¹±\n",
    "\t\t\"keep_tokens\": 1,\n",
    "\n",
    "\t\t# è®­ç»ƒçš„åˆ†è¾¨ç‡\n",
    "\t\t\"resolution\": 1024,\n",
    "\t\t\"flip_aug\": False,\n",
    "\t\t\"caption_extension\": \".txt\",\n",
    "\t\t\"enable_bucket\": True,\n",
    "\t\t\"bucket_no_upscale\": True,\n",
    "\t\t\"bucket_reso_steps\": 64,\n",
    "\t\t\"min_bucket_reso\": 256,\n",
    "\t\t\"max_bucket_reso\": 4096,\n",
    "\t},\n",
    "\t# æ•°æ®é›†ï¼Œå¯è®¾ç½®å¤šä¸ªæ•°æ®é›†\n",
    "\t\"datasets\": [{\n",
    "\t\t\"subsets\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t# æ•°æ®é‡å¤å‡ æ¬¡\n",
    "\t\t\t\t\"num_repeats\": 5,\n",
    "\t\t\t\t# æ•°æ®é›†è·¯å¾„ï¼Œæœ€ç»ˆä¼šè‡ªåŠ¨å¤åˆ¶åˆ°tmpdirç›®å½•ä¸‹ä½¿ç”¨\n",
    "\t\t\t\t\"image_dir\": \"D:\\\\GITHUB\\\\sd-scripts\\\\samples\\\\juzhi\",\n",
    "\t\t\t\t# æ˜¯å¦ä½¿ç”¨mepåŠ å¯†ï¼Œè®¾ä¸ºNoneè¡¨ç¤ºä¸ä½¿ç”¨ï¼Œè®¾ä¸ºtrueè¡¨ç¤ºä½¿ç”¨\n",
    "\t\t\t\t\"cache_info\": None,\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ab26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Train config saved to database/working\\juzhisam\\configs\\training_config.toml\n",
      "ğŸ“„ Dataset config saved to database/working\\juzhisam\\configs\\dataset_config.toml\n",
      "Configuration already exists at database/working\\juzhisam\\configs\\accelerate_config\\config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "ğŸ“„ Accelerate config saved to database/working\\juzhisam\\configs\\accelerate_config\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "config_dict[\"optimizer_arguments\"][\"learning_rate\"] = config_dict[\"network_arguments\"][\"unet_lr\"]\n",
    "config_dict[\"training_arguments\"][\"full_bf16\"] = (config_dict[\"training_arguments\"][\"mixed_precision\"] == \"bf16\")\n",
    "config_dict[\"training_arguments\"][\"full_fp16\"] = (config_dict[\"training_arguments\"][\"mixed_precision\"] == \"fp16\")\n",
    "\n",
    "workingdir = os.path.join(root_dir, lora_name)\n",
    "configdir = os.path.join(workingdir, \"configs\")\n",
    "logdir = os.path.join(workingdir, \"logs\")\n",
    "outputdir = os.path.join(workingdir, \"outputs\")\n",
    "datasetdir = os.path.join(tmp_dir, \"dataset\")\n",
    "\n",
    "for x in [workingdir, configdir, logdir, outputdir, datasetdir]:\n",
    "\tos.makedirs(x, exist_ok = True)\n",
    "\n",
    "config_dict[\"saving_arguments\"][\"output_dir\"] = os.path.abspath(outputdir)\n",
    "config_dict[\"saving_arguments\"][\"logging_dir\"] = os.path.abspath(logdir)\n",
    "\n",
    "resolution = dataset_dict[\"general\"][\"resolution\"]\n",
    "temp_resolution = round(resolution / 128) * 128\n",
    "if (resolution != temp_resolution):\n",
    "\tresolution = temp_resolution\n",
    "\tprint(\"âš ï¸ resolution is rouned to nearest step: \", resolution)\n",
    "\tdataset_dict[\"general\"][\"resolution\"] = resolution\n",
    "\n",
    "for i in range(len(dataset_dict[\"datasets\"][0][\"subsets\"])):\n",
    "\ttargetfolder = os.path.join(datasetdir, str(i))\n",
    "\tif os.path.exists(targetfolder):\n",
    "\t\tshutil.rmtree(targetfolder)\n",
    "\tshutil.copytree(dataset_dict[\"datasets\"][0][\"subsets\"][i][\"image_dir\"], targetfolder)\n",
    "\tdataset_dict[\"datasets\"][0][\"subsets\"][i][\"image_dir\"] = os.path.abspath(targetfolder)\n",
    "\n",
    "def CleanConfigAndSave(name: str, filename: str, config_dict: dict):\n",
    "\tfor key in config_dict:\n",
    "\t\tif isinstance(config_dict[key], dict):\n",
    "\t\t\tconfig_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
    "\t\n",
    "\twith open(filename, \"w\") as f:\n",
    "\t\tf.write(toml.dumps(config_dict))\n",
    "\n",
    "\tprint(f\"ğŸ“„ {name} config saved to {filename}\")\n",
    "\n",
    "config_file = os.path.join(configdir, \"training_config.toml\")\n",
    "CleanConfigAndSave(\"Train\", config_file, config_dict)\n",
    "\n",
    "dataset_file = os.path.join(configdir, \"dataset_config.toml\")\n",
    "CleanConfigAndSave(\"Dataset\", dataset_file, dataset_dict)\n",
    "\n",
    "accelerate_file = os.path.join(configdir, \"accelerate_config\", \"config.yaml\")\n",
    "from accelerate.utils import write_basic_config\n",
    "write_basic_config(save_location=accelerate_file)\n",
    "print(f\"ğŸ“„ Accelerate config saved to {accelerate_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bab4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ Starting trainer...\n"
     ]
    }
   ],
   "source": [
    "print(\"â­ Starting trainer...\")\n",
    "\n",
    "#!accelerate launch --config_file={accelerate_file} --num_cpu_threads_per_process=1 --mixed_precision={config_dict[\"training_arguments\"][\"mixed_precision\"]} train_network_xl_wrapper.py --dataset_config={dataset_file} --config_file={config_file} --mep_key {encrypt_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31ca325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train_network_xl_wrapper.py --dataset_config={dataset_file} --config_file={config_file} --mep_key {encrypt_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
